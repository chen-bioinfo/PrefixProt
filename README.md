# PrefixProt
üìãControllable Protein Design by Prefix-Tuning Protein Language Models

## üìò Abstract
The design of novel proteins with tailored functionalities presents a transformative approach to addressing pressing biomedical challenges. In this study, we propose PrefixProt, a framework for controllable protein design that employs prefix tuning to learn virtual tokens as control tags. These virtual tokens are adaptively tailored to diverse protein properties through a data-driven manner and can be combinatorially integrated to enable multi-objective control over protein generation. The effectiveness of PrefixProt was validated through extensive experiments encompassing both protein structure design (e.g. alpha-helix or beta-sheet topologies) and protein function design (e.g. antimicrobial or anticancer peptide activities). Benchmark results demonstrate that prefix virtual tokens efficiently guide the pre-trained ProtLM by optimizing a smaller number of trainable parameters, outperforming other parameter-efficient fine-tuning methods and text-guided ProtLMs, particularly in scenarios with limited data availability. More importantly, the compositional flexibility of virtual tokens facilitates the generation of proteins with multiple target properties, substantially expanding the scope of design possibilities. PrefixProt establishes a robust framework for de novo protein design, with promising applications in drug discovery and biomedicine.

## üß¨ Model Structure
<div align=center><img src=img/framework1.png></div>

## üöÄ Train
```
# 1. Creating a virtual environment
conda activate prefixprot

# 2. the key elements of 'prefixprot' operating environment are listed below(python==3.8):
transformers==4.28.1
torch==1.9.0+cu111 (You can download it from the pytorch(https://pytorch.org/get-started/previous-versions) )
peft==0.3.0
modlamp==4.3.0
pandas==1.4.0
datasets==2.12.0
numpy==1.23.5
tqdm==4.65.0
matplotlib==3.7.1
seaborn==0.12.2
tensorboard==2.13.0

# 3. Clone this repository
git clone https://github.com/chen-bioinfo/PrefixProt.git
cd PrefixProt

# 4. Download the pre-trained protein language models ProtGPT2 from the link (https://drive.google.com/drive/u/2/folders/1XQDxrd7oMlIOZ-veH69IL8HoH0u09rUj or 
https://huggingface.co/nferruz/ProtGPT2/tree/main); Put it in the 'PrefixProt' folder;

# 5. Train model
cd PrefixProt/Task
python prefix_tuning_prot.py
```

## üöÄ Generate
```
# 1. Download the finetune model and prefix tuning model from the link (https://drive.google.com/drive/u/2/folders/1riMdbGbmfhpyrjI3GplwvoLxDeqVt4YD); 
Put it in the 'PrefixProt' folder;

# 2. generate sequence
cd PrefixProt/generate
python 01-generate_finetune.py 
python 02-generate_prefix.py

# 3.You can get the predicted structure of the protein generated by the model, as well as the structure after RELAX at the following link 
(https://drive.google.com/drive/u/2/folders/1LZlJ9c24w5J2WgWcDGbN0q2Fm5qvZfeC); 
Unzip it into the 'PrefixProt/generate/Allalpha/' folder;
```

## üßê Analysis
The analysis codes are all located in the folder 'PrefixProt/generate'

| File name | Description |
| ----------- | ----------- |
| 03.1-fold_pred.py      | Predicting protein structure using esmfold       |
| 03.2-dssp_pred.py   | Get secondary structure via dssp tool        |
| 03.3-fold(vis).ipynb     | Visualization of secondary structure distribution       |
| 04.1-rosetta_relax.py     | Relax of protein structures using pyrosetta       |
| 04.2-rosetta_energy.py   | Calculating protein energy after RELAX        |
| 04.3-rosetta(vis).ipynb   | Visualizing the energy distribution of generated proteins        |
| 05.1-RAMA.py   | Get Ramachandran plot       |
| 05.2-RAMA(vis).ipynb   | Visualizing the Ramachandran plot   |
| 06-AMP_analysis.ipynb   | Analysis of generated AMP sequences  |


## ‚úèÔ∏è Citation
If you use this code or our model for your publication, please cite the original paper:
